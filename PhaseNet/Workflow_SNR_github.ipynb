{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d724847-c29f-4d95-8705-af3ea837c6fb",
   "metadata": {},
   "source": [
    "## Notebook to compute ML picks for INGV events in Norcia Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ffc659e-ecd5-44da-be41-bb27cee51fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from obspy.core.event import  Event, Origin, Magnitude, Pick, WaveformStreamID\n",
    "from obspy import Catalog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from obspy import read_events\n",
    "from obspy import read_inventory\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.clients.filesystem.sds import Client as sdsclient\n",
    "from obspy.core import Trace, Stream, Stats\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b5a50-a91d-4bd8-888e-d2d684630764",
   "metadata": {},
   "source": [
    "### Def to download waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec7f61a-480c-4ffe-8e62-ad68fb77d50a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download(starttime, endtime, inventory):\n",
    "    max_retry = 10\n",
    "    stream = obspy.Stream()\n",
    "    for network in inventory:\n",
    "        for station in network:\n",
    "            # print(f\"********{network.code}.{station.code}********\")\n",
    "            retry = 0\n",
    "            while retry < max_retry:\n",
    "                try:\n",
    "                    ch=inventory.select(station=station.code).get_contents()['channels'][0].split('.')[-1][:2]+\"?\"\n",
    "                    if network.code ==\"YR\":\n",
    "                        tmp = sdsYR.get_waveforms(\n",
    "                            network=network.code, \n",
    "                            station=station.code, \n",
    "                            location=\"\", \n",
    "                            channel=ch, \n",
    "                            starttime=starttime, \n",
    "                            endtime=endtime\n",
    "                        )\n",
    "                    else:\n",
    "                        tmp = sds.get_waveforms(\n",
    "                            network=network.code, \n",
    "                            station=station.code, \n",
    "                            location=\"\", \n",
    "                            channel=ch, \n",
    "                            starttime=starttime, \n",
    "                            endtime=endtime\n",
    "                        )\n",
    "                    if len(tmp) > 0:\n",
    "                        tmp.merge(method=0,fill_value=0)\n",
    "                    for trace in tmp:\n",
    "                        if trace.stats.sampling_rate != 100:\n",
    "                            trace = trace.interpolate(100, method=\"linear\")\n",
    "                    stream += tmp\n",
    "                    \n",
    "                    break\n",
    "                except Exception as err:\n",
    "                    print(\"Error {}.{}: {}\".format(network.code, station.code, err))\n",
    "                    message = \"No data available for request.\"\n",
    "                    if str(err)[: len(message)] == message:\n",
    "                        break\n",
    "                    retry += 1\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "            if retry == max_retry:\n",
    "                print(f\"{fname}: MAX {max_retry} retries reached : {network.code}.{station.code}\")\n",
    "    stream.merge(method=0,fill_value=0)\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90a0376-812c-42ab-bae1-1868ac917cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_zero_stream(network, station, channels, start_time, end_time, sampling_rate):\n",
    "    stream = Stream()\n",
    "\n",
    "    # Create a Trace for each channel\n",
    "    for channel in channels:\n",
    "        stats = Stats()\n",
    "        stats.network = network\n",
    "        stats.station = station\n",
    "        stats.channel = channel\n",
    "        stats.sampling_rate = sampling_rate\n",
    "        stats.starttime = UTCDateTime(start_time)\n",
    "        # stats.endtime = UTCDateTime(end_time)\n",
    "\n",
    "        # Create a Trace with zeros\n",
    "        trace_data = [0.0] * int((end_time - start_time) * sampling_rate)\n",
    "        trace = Trace(data=np.array(trace_data), header=stats)\n",
    "\n",
    "        stream.append(trace)\n",
    "\n",
    "    return stream\n",
    "\n",
    "\n",
    "# Print the resulting stream\n",
    "# print(zero_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c76c9cba-045d-476e-a33b-ce5943d3486b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def findpicks(pddataframe, picker,threshold,inventory):\n",
    "    name=\"pn\"\n",
    "    Plist = []\n",
    "    Slist = []\n",
    "    Pproblist = []\n",
    "    Sproblist = []\n",
    "    mseedlist = []\n",
    "    # distlist = []\n",
    "    # Mlist = []\n",
    "    for i, row in pddataframe.iterrows():\n",
    "        sta = row['Station']\n",
    "        Pori = row['P pick']\n",
    "        Sori = row['S pick']\n",
    "        # print(sta,Pori, Sori)\n",
    "        # stainv = inv.select(station=sta)\n",
    "        # if len(stainv.networks) > 0:\n",
    "        if pd.notna(Pori):\n",
    "            t0 = Pori - 20\n",
    "            t1 = Pori + 40\n",
    "        else:\n",
    "            t0 = Sori - 20\n",
    "            t1 = Sori + 40\n",
    "\n",
    "        # inv = inv_ingv_hh.select(station=sta,starttime=t0, endtime=t1)\n",
    "        # inv = inv_ingv_hh.select(station=sta)\n",
    "        inv = inventory.select(station=sta,starttime=t0, endtime=t1)\n",
    "        # print(sta,inv)\n",
    "        for net in inv:\n",
    "            if net.code == \"8P\":\n",
    "                net.code = \"IV\"\n",
    "\n",
    "        mseed = download(t0, t1, inv)\n",
    "        # print(sta, len(mseed))\n",
    "        # mseed = st.select(station=sta)\n",
    "        ### if len(mseed)=0, create a stream of zeroes\n",
    "        if len(mseed) == 0:\n",
    "            channels=[]\n",
    "            for net in inv:\n",
    "                network = net.code\n",
    "                for sta in net:\n",
    "                    station = sta.code\n",
    "                    for ch in sta:\n",
    "                        channels.append(ch.code)\n",
    "                                               \n",
    "            start_time = t0\n",
    "            end_time = t1\n",
    "            sampling_rate = 100.0  # Replace with your desired sampling rate\n",
    "\n",
    "            mseed = create_zero_stream(network, station, channels, start_time, end_time, sampling_rate)\n",
    "\n",
    "            \n",
    "        # Dist = calc_vincenty_inverse(lat_eve, lon_eve, mseed[0].stats.sac.stla, mseed[0].stats.sac.stlo)[0] / 1000\n",
    "        # distlist.append(Dist)\n",
    "        mseedlist.append(mseed[0].get_id())\n",
    "        for trace in mseed:\n",
    "            if trace.stats.sampling_rate != 100:\n",
    "                trace.resample(100.)\n",
    "            # mseed = downlad(Pori, stainv)\n",
    "\n",
    "        picks = picker.classify(mseed, overlap=2800, stacking='max', P_threshold=threshold, S_threshold=threshold).picks\n",
    "        # picks = picker.classify(mseed, P_threshold=threshold, S_threshold=threshold).picks\n",
    "        deltap = 1e30\n",
    "        deltas = 1e30\n",
    "        PP = None\n",
    "        Pprob=None\n",
    "        if pd.notna(Pori):  # Check if Pori is not NaN\n",
    "            for p in picks:\n",
    "                if p.phase == 'P':\n",
    "                    if abs(Pori - obspy.UTCDateTime(p.peak_time)) < deltap:\n",
    "                        PP = obspy.UTCDateTime(p.peak_time)\n",
    "                        Pprob = p.peak_value\n",
    "                        deltap = abs(Pori - PP)\n",
    "        # Plist.append(PP)\n",
    "            Plist.append(PP)\n",
    "            Pproblist.append(Pprob)\n",
    "        else:\n",
    "            Plist.append(None)\n",
    "            Pproblist.append(None)\n",
    "\n",
    "        if pd.notna(Sori):  # Check if Sori is not NaN\n",
    "            SS = None\n",
    "            Sprob=None\n",
    "            for p in picks:\n",
    "                if p.phase == 'S':\n",
    "                    if abs(Sori - obspy.UTCDateTime(p.peak_time)) < deltas:\n",
    "                        SS = obspy.UTCDateTime(p.peak_time)\n",
    "                        Sprob = p.peak_value\n",
    "                        deltas = abs(Sori - SS)\n",
    "            Slist.append(SS)\n",
    "            Sproblist.append(Sprob)\n",
    "        else:\n",
    "            Slist.append(None)\n",
    "            Sproblist.append(None)\n",
    "\n",
    "    namep = \"P \" + name\n",
    "    names = \"S \" + name\n",
    "    pddataframe['id'] = mseedlist\n",
    "    # pddataframe['Dist'] = distlist\n",
    "    pddataframe[namep] = Plist\n",
    "    pddataframe[names] = Slist\n",
    "    pddataframe['Pproba'] = Pproblist\n",
    "    pddataframe['Sproba'] = Sproblist\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f7afd5-a81d-49db-992e-c2833445fa07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baaf8556-7259-45c5-a4db-ee2603aba6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_event(df_local, origintime, eve_id, savelocaldirectory):\n",
    "    # print(origintime,test)\n",
    "    timedelta = 2\n",
    "\n",
    "    obsdir = \"/home/jovyan/shared/users/spina/Norcia/github/OBS/\"+savelocaldirectory+\"/\"\n",
    "\n",
    "    if not os.path.exists(obsdir):\n",
    "        os.makedirs(obsdir)\n",
    "\n",
    "    cat = Catalog()\n",
    "    cat.description = \"Norcia_test\"\n",
    "    phaselist = ['P', 'S']\n",
    "\n",
    "    e = Event()\n",
    "    e.event_type = \"Earthquake\"\n",
    "    e.resource_id = eve_id\n",
    "    o = Origin()\n",
    "    o.time = origintime\n",
    "\n",
    "    for i, row in df_local.iterrows():\n",
    "        if pd.notna(row['P pick']) and (row['P pn'] != ''):\n",
    "            if abs(row['P pick'] - row['P pn']) <= timedelta:\n",
    "                wav_id = WaveformStreamID(\n",
    "                    station_code=row['Station'],\n",
    "                    channel_code=\"Z\",\n",
    "                    network_code=row['id'].split('.')[0]\n",
    "                )\n",
    "                e.picks.append(Pick(\n",
    "                    time=row['P pn'],\n",
    "                    waveform_id=wav_id,\n",
    "                    phase_hint='P',\n",
    "                    evaluation_mode=\"automatic\",\n",
    "                    time_errors=0.02\n",
    "                ))\n",
    "\n",
    "        if pd.notna(row['S pick']) and (row['S pn'] != ''):\n",
    "            if abs(row['S pick'] - row['S pn']) <= timedelta:\n",
    "                wav_id = WaveformStreamID(\n",
    "                    station_code=row['Station'],\n",
    "                    channel_code=\"N\",\n",
    "                    network_code=row['id'].split('.')[0]\n",
    "                )\n",
    "                e.picks.append(Pick(\n",
    "                    time=row['S pn'],\n",
    "                    waveform_id=wav_id,\n",
    "                    phase_hint='S',\n",
    "                    evaluation_mode=\"automatic\",\n",
    "                    time_errors=0.04\n",
    "                ))\n",
    "\n",
    "    # print(e.picks)\n",
    "    if len(e.picks) > 0:\n",
    "        fileOBS = obsdir + \"Norcia_test_\" + str(origintime) + \"_\" + \".phs\"\n",
    "        e.write(fileOBS, format=\"NLLOC_OBS\")\n",
    "\n",
    "        with open(fileOBS, \"r+\") as f: s = f.read(); f.seek(0); f.write(\"PUBLIC_ID \"+str(e.resource_id)+\"\\n\" + s)\n",
    "    else:\n",
    "        print('No picks for event',e.resource_id)\n",
    "        f = open('no_event.txt', 'a')\n",
    "        f.write(str(e.resource_id)+\"\\n\")\n",
    "        f.close()\n",
    "# Example usage:\n",
    "# replace df1, origintime, and test with your actual data\n",
    "# write_event(df1, origintime_value, test_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bea652e-4fcc-42c0-b654-26bc5892a5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_components(stream):\n",
    "\n",
    "#################################################\n",
    "# Check if E and N component are foud in stream #\n",
    "#################################################\n",
    "\n",
    "    check = stream.select(component='[E,N,1,2]')\n",
    "    \n",
    "    if len(check) == 2 :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "# stream = mseed  # Your ObsPy Stream object here\n",
    "# has_en_components = check_components(stream)\n",
    "# print(f\"Stream has E or N components: {has_en_components}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "474acd8a-dc2a-48fb-ac2d-f2abf22cfd0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_data_length(stream, threshold=400):\n",
    "    for trace in stream:\n",
    "        if len(trace.data) <= threshold:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# # Example usage:\n",
    "# if check_data_length(mseed):\n",
    "#     print(\"All traces have data length larger than 3000.\")\n",
    "# else:\n",
    "#     print(\"Some traces have data length less than or equal to 3000.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78ca41e3-95a5-4382-92d4-29c5db2554da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SNR_dataframe(dataframe,inventory,lenght):\n",
    "    \"\"\"\n",
    "    The function calculates the signal-to-noise ratio (SNR) of a given time series data.\n",
    "    \n",
    "    :param tr: The variable \"tr\" is likely a time series data object, such as a waveform or seismogram.\n",
    "    It contains the data that we want to calculate the signal-to-noise ratio (SNR) for\n",
    "    :param P_sample: P_sample is the sample number where the noise portion of the signal starts\n",
    "    :param S_sample: The starting sample index of the signal window\n",
    "    :param npts_snr: The parameter \"npts_snr\" represents the number of data points used to calculate the\n",
    "    signal-to-noise ratio (SNR)\n",
    "    :return: the signal-to-noise ratio (SNR) calculated using the provided parameters.\n",
    "    \"\"\"\n",
    "    #\n",
    "    \n",
    "    filt=[0.05,0.1,0.2,0.5,1,2]\n",
    "    buffer_samples = 0.2\n",
    "    ampl_lenght = 10\n",
    "\n",
    "    Psnr_final=[]\n",
    "    Pfreq_final=[]\n",
    "    Ssnr_final=[]\n",
    "    Sfreq_final=[]\n",
    "\n",
    "    for i, row in dataframe.iterrows():\n",
    "        sta = row['Station']\n",
    "        Pori = row['P pick']\n",
    "        Sori = row['S pick']\n",
    "        # print(sta,Pori,Sori)\n",
    "        if pd.notna(Pori):\n",
    "            start_signal = Pori - buffer_samples\n",
    "            end_signal = Pori + lenght - buffer_samples\n",
    "            start_noise = Pori - (lenght + buffer_samples)\n",
    "            end_noise = Pori - buffer_samples\n",
    "\n",
    "            t0 = start_noise-1\n",
    "            t1 = end_signal+1\n",
    "            inv = inventory.select(station=sta,starttime=t0, endtime=t1)\n",
    "            for net in inv:\n",
    "                if net.code == \"8P\":\n",
    "                    net.code = \"IV\"\n",
    "\n",
    "            mseed = download(t0, t1, inv)\n",
    "            mseed = mseed.select(component=\"[E,N,1,2]\")\n",
    "            # mseed.plot();\n",
    "            # print(sta,mseed)\n",
    "            # print('comp',check_components(mseed))\n",
    "            # print('len',check_data_length(mseed))\n",
    "\n",
    "            if (check_components(mseed)) and (check_data_length(mseed)):\n",
    "                snrlist=[]\n",
    "                for f in filt:\n",
    "                    snr=0.\n",
    "                    stream_filt=mseed.copy().filter('highpass',freq=f)\n",
    "                    for t in stream_filt:\n",
    "                        tr = t.copy().trim(starttime=start_signal,endtime=end_signal)\n",
    "                        signal = np.absolute(tr.data)\n",
    "                        sig_95per = np.percentile(signal, 95)\n",
    "\n",
    "                        tr = t.copy().trim(starttime=start_noise,endtime=end_noise)\n",
    "                        noise = np.absolute(tr.data)\n",
    "                        noi_95per = np.percentile(noise, 95)\n",
    "                        snrtmp = 20.0 * np.log10(sig_95per/noi_95per)\n",
    "                        snr+=snrtmp\n",
    "                    snr=snr/2.\n",
    "                    snrlist.append(snr)\n",
    "                snrindex=snrlist.index(max(snrlist))\n",
    "                Psnr_final.append(snrlist[snrindex])\n",
    "                Pfreq_final.append(filt[snrindex])\n",
    "            else:\n",
    "                # mseed.plot();\n",
    "                # print(sta,mseed)\n",
    "                # print('comp',check_components(mseed))\n",
    "                # print('len',check_data_length(mseed))\n",
    "                Psnr_final.append(\"NTA\")\n",
    "                Pfreq_final.append(\"NTA\")\n",
    "        else:\n",
    "            Psnr_final.append(None)\n",
    "            Pfreq_final.append(None)\n",
    "\n",
    "            \n",
    "        if pd.notna(Sori):\n",
    "            start_signal = Sori - buffer_samples\n",
    "            end_signal = Sori + lenght - buffer_samples\n",
    "            start_noise = Sori - (lenght + buffer_samples)\n",
    "            end_noise = Sori - buffer_samples\n",
    "\n",
    "            t0 = start_noise-1\n",
    "            t1 = end_signal+1\n",
    "            inv = inventory.select(station=sta,starttime=t0, endtime=t1)\n",
    "            for net in inv:\n",
    "                if net.code == \"8P\":\n",
    "                    net.code = \"IV\"\n",
    "\n",
    "            mseed = download(t0, t1, inv)\n",
    "            mseed = mseed.select(component=\"[E,N,1,2]\")\n",
    "\n",
    "            # print(sta,mseed)\n",
    "            # print('comp',check_components(mseed))\n",
    "            # print('len',check_data_length(mseed))\n",
    "\n",
    "            if (check_components(mseed)) and (check_data_length(mseed)):\n",
    "                snrlist=[]\n",
    "                for f in filt:\n",
    "                    snr=0.\n",
    "                    stream_filt=mseed.copy().filter('highpass',freq=f)\n",
    "                    for t in stream_filt:\n",
    "                        tr = t.copy().trim(starttime=start_signal,endtime=end_signal)\n",
    "                        signal = np.absolute(tr.data)\n",
    "                        sig_95per = np.percentile(signal, 95)\n",
    "\n",
    "                        tr = t.copy().trim(starttime=start_noise,endtime=end_noise)\n",
    "                        noise = np.absolute(tr.data)\n",
    "                        noi_95per = np.percentile(noise, 95)\n",
    "                        snrtmp = 20.0 * np.log10(sig_95per/noi_95per)\n",
    "                        snr+=snrtmp\n",
    "                    snr=snr/2.\n",
    "                    snrlist.append(snr)\n",
    "                snrindex=snrlist.index(max(snrlist))\n",
    "                Ssnr_final.append(snrlist[snrindex])\n",
    "                Sfreq_final.append(filt[snrindex])\n",
    "            else:\n",
    "                # mseed.plot();\n",
    "                # print(sta,mseed)\n",
    "                # print('comp',check_components(mseed))\n",
    "                # print('len',check_data_length(mseed))\n",
    "                Ssnr_final.append(\"NTA\")\n",
    "                Sfreq_final.append(\"NTA\")\n",
    "        else:\n",
    "            Ssnr_final.append(None)\n",
    "            Sfreq_final.append(None)\n",
    "\n",
    "    dataframe['Psnr'] = Psnr_final\n",
    "    dataframe['Pfreq'] = Pfreq_final\n",
    "    dataframe['Ssnr'] = Ssnr_final\n",
    "    dataframe['Sfreq'] = Sfreq_final\n",
    "\n",
    "    dataframe['P_terr'] = dataframe['P pick'] - dataframe['P pn']\n",
    "    dataframe['S_terr'] = dataframe['S pick'] - dataframe['S pn']\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e160259e-1152-4ce0-930d-a9e4cab4dc6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_residual_snr(local_dataframe):\n",
    "\n",
    "    df_p = local_dataframe.dropna(subset=['P pick', 'P pn', 'Pproba', 'Psnr'])\n",
    "    df_s = local_dataframe.dropna(subset=['S pick', 'S pn', 'Sproba', 'Ssnr'])\n",
    "\n",
    "    # Calculate log of SNR and residuals\n",
    "    df_p['log_Psnr'] = np.log10(df_p['Psnr'])\n",
    "    df_s['log_Ssnr'] = np.log10(df_s['Ssnr'])\n",
    "    # df_p['P_terr'] = df_p['P pick'] - df_p['P pn']\n",
    "    # df_s['S_terr'] = df_s['S pick'] - df_s['S pn']\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot for P data\n",
    "    sc_p = axs[0].scatter(df_p['P_terr'], df_p['log_Psnr'], c=df_p['Pproba'], cmap='viridis', edgecolor='black')\n",
    "    axs[0].set_xlabel('P Residual (manual-phasnet)')\n",
    "    axs[0].set_ylabel('Log P SNR')\n",
    "    axs[0].set_title('P Residual vs Log P SNR')\n",
    "    fig.colorbar(sc_p, ax=axs[0], label='P Probability')\n",
    "\n",
    "    # Plot for S data\n",
    "    sc_s = axs[1].scatter(df_s['S_terr'], df_s['log_Ssnr'], c=df_s['Sproba'], cmap='plasma', edgecolor='black')\n",
    "    axs[1].set_xlabel('S Residual (manual-phasnet)')\n",
    "    axs[1].set_ylabel('Log S SNR')\n",
    "    axs[1].set_title('S Residual vs Log S SNR')\n",
    "    fig.colorbar(sc_s, ax=axs[1], label='S Probability')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ec1f55-98b9-460f-a660-083b9400e3fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "client = Client(\"INGV\")\n",
    "sds=sdsclient(\"/home/jovyan/data/sds/\")\n",
    "sdsYR=sdsclient(\"/home/jovyan/data/iris/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b1938b-b758-4382-9258-868ed131b337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-20T00:00:00.000000Z 2016-10-21T00:00:00.000000Z\n"
     ]
    }
   ],
   "source": [
    "starttime=UTCDateTime(\"2016-10-20T00:00:00\")\n",
    "endtime=UTCDateTime(\"2016-10-21T00:00:00\")\n",
    "# endtime=UTCDateTime(\"2016-12-01T00:00:00\")\n",
    "print(starttime,endtime)\n",
    "nday=int((endtime-starttime)/86400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3076d89-0ca3-424e-a2e7-b51730d2ce6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8be6b332-d1bd-43ff-8988-e06ea8983373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INVE='./INVENTORY/*.xml'\n",
    "\n",
    "ii  = glob.glob(INVE)\n",
    "inv=obspy.Inventory()\n",
    "\n",
    "for e in ii:\n",
    "    inv+=read_inventory(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "219c2372-72fe-4c87-963b-94b0e9718fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stalist=set()\n",
    "# for net in invent_new.select(channel=\"*Z\"):\n",
    "for net in inv.select(channel=\"*Z\"):\n",
    "    for sta in net:\n",
    "        stalist.add(sta.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca577e4-decc-4e4b-92de-0af820e2ea7e",
   "metadata": {},
   "source": [
    "## Read INGV catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36dec8e4-5713-4a7a-b82c-ecb3d73d1542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catINGV = read_events(\"./catalog_ingv.xml\")\n",
    "catINGV = Catalog(sorted(catINGV, key=lambda e: e.origins[0].time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e060ac5a-ccb4-4c0c-81af-f46f3226d692",
   "metadata": {},
   "source": [
    "### Load Seisbench model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b23a6e02-06d8-4a04-aea8-00de35b419be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/seisbench/models/base.py:489: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_weights = torch.load(f\"{path_pt}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original PhaseNet model from Zhu et al. (2018). Originally published under MIT License. Original available at https://github.com/AI4EPS/PhaseNet/tree/master/model/190703-214543 . \n",
      "\n",
      "Converted to SeisBench by Jannes Münchmeyer (munchmej@univ-grenoble-alpes.fr) with help from Sacha Lapins, Yiyuan Zhong, and Jun Zhu\n"
     ]
    }
   ],
   "source": [
    "import seisbench.models as sbm\n",
    "\n",
    "picker_pno = sbm.PhaseNet.from_pretrained(\"original\")\n",
    "picker_pni = sbm.PhaseNet.from_pretrained(\"instance\")\n",
    "\n",
    "picker_pno.cuda()\n",
    "picker_pni.cuda()\n",
    "print(picker_pno.weights_docstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc2a7df-9e4c-4891-81f6-e1eba8c3d471",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract picks from INGV catalog correspondig to arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "011d0f77-0ada-49b9-8642-5354438d6733",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shared/users/spina/Norcia/githib/NLLoc/SNR/2016-10-20T23:40:14.010000Z.csv\n"
     ]
    }
   ],
   "source": [
    "## Define model a\n",
    "picker=picker_pni\n",
    "thresholds=0.1\n",
    "dirsave='PN_INST_01'\n",
    "offset=2\n",
    "for curreve in catINGV:\n",
    "    staall = set([])\n",
    "    ingvpick = []\n",
    "    data_dict = {}\n",
    "    event_id_str = str(curreve.resource_id)\n",
    "    evento_id = event_id_str.split(\"eventId=\")[-1]\n",
    "    ori = curreve.origins[0]\n",
    "    arrivals = ori.arrivals\n",
    "    picks=curreve.picks\n",
    "    t = ori.time\n",
    "    lon = ori.longitude\n",
    "    lat = ori.latitude\n",
    "    dep = ori.depth\n",
    "    inventory=read_inventory('./INVENTORY/inventory_ingv'+str(t.julday)+\".xml\")\n",
    "    stalist=[]\n",
    "    for net in inventory.select(channel=\"*Z\"):\n",
    "        for sta in net:\n",
    "            stalist.append(sta.code)\n",
    "    for ar in arrivals:\n",
    "        if (ar.phase in ['P','S','Pn','Sn','Pg','Sg']):# and ar.time_weight >= 0.00001):\n",
    "            pi = [p for p in picks if p.resource_id == ar.pick_id][0]\n",
    "            sta = pi.waveform_id.station_code\n",
    "            staall.add(sta)\n",
    "            if sta in stalist:\n",
    "                ingvpick.append(pi)\n",
    "\n",
    "    # Initialize the 'S pick' column with np.nan in the dictionary\n",
    "    for pick in ingvpick:\n",
    "        station_code = pick.waveform_id.station_code\n",
    "        pick_time = pick.time\n",
    "\n",
    "        # Check phase_hint and update the dictionary accordingly\n",
    "        if (pick.phase_hint == 'P') or (pick.phase_hint == 'Pg') or (pick.phase_hint == 'Pn'):\n",
    "            if station_code not in data_dict:\n",
    "                data_dict[station_code] = {'Station': station_code, 'P pick': pick_time, 'S pick': np.nan}\n",
    "            else:\n",
    "                data_dict[station_code]['P pick'] = pick_time\n",
    "        elif (pick.phase_hint == 'S') or (pick.phase_hint == 'Sg') or (pick.phase_hint == 'Sn'):\n",
    "            if station_code not in data_dict:\n",
    "                data_dict[station_code] = {'Station': station_code, 'P pick': np.nan, 'S pick': pick_time}\n",
    "            else:\n",
    "                data_dict[station_code]['S pick'] = pick_time\n",
    "\n",
    "\n",
    "# Convert the dictionary to a list of dictionaries and create a DataFrame\n",
    "    df_picks = pd.DataFrame(list(data_dict.values()))\n",
    "    # print(df_picks)\n",
    "\n",
    "# Now call phasenet to find the picks         \n",
    "    findpicks(df_picks,picker,thresholds,inventory)\n",
    "    # print(df_picks)\n",
    "    # dfn_snr = SNR_dataframe(dfn,inv,2)\n",
    "    SNR_dataframe(df_picks,inv,2)\n",
    "    # print(df_picks)\n",
    "    \n",
    "    snr_dir='/home/jovyan/shared/users/spina/Norcia/github/NLLoc/SNR/'\n",
    "    if not os.path.exists(snr_dir):\n",
    "        os.makedirs(snr_dir)\n",
    "\n",
    "    nname=snr_dir+str(ori.time)+'.csv'\n",
    "    print(nname)\n",
    "    # dfn_snr.to_csv(nname, index=False)\n",
    "    df_picks.to_csv(nname, index=False)\n",
    "    # print(dfn)\n",
    "            # for p in pick:\n",
    "    #     print(p.waveform_id.station_code,p.waveform_id.channel_code ,p.phase_hint,p.time)\n",
    "    # Now write the event\n",
    "\n",
    "    # write_event(dfn_snr, ori.time, evento_id, dirsave)\n",
    "\n",
    "    # print(len(ingvpick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "101448c2-5aca-40d4-bb7a-2a6427bfd5da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " plot_residual_snr(df_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc7d160f-617a-4152-b3c3-2fe0cea40667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the relevant columns\n",
    "df_p = df_picks.dropna(subset=['P pick', 'P pn', 'Pproba', 'Psnr'])\n",
    "df_s = df_picks.dropna(subset=['S pick', 'S pn', 'Sproba', 'Ssnr'])\n",
    "\n",
    "# Calculate log of SNR and residuals\n",
    "df_p['log_Psnr'] = np.log10(df_p['Psnr'])\n",
    "df_s['log_Ssnr'] = np.log10(df_s['Ssnr'])\n",
    "# df_p['P_terr'] = df_p['P pick'] - df_p['P pn']\n",
    "# df_s['S_terr'] = df_s['S pick'] - df_s['S pn']\n",
    "\n",
    "# Define the discrete color scale and normalization\n",
    "cmap_p = plt.cm.viridis\n",
    "cmap_s = plt.cm.plasma\n",
    "bounds = np.arange(0, 1.1, 0.1)\n",
    "norm = BoundaryNorm(boundaries=bounds, ncolors=cmap_p.N, clip=True)\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot for P data\n",
    "sc_p = axs[0].scatter(df_p['P_terr'], df_p['log_Psnr'], c=df_p['Pproba'], cmap=cmap_p, norm=norm, edgecolor='black')\n",
    "axs[0].set_xlabel('P Residual (manual-phasnet)')\n",
    "axs[0].set_ylabel('Log P SNR')\n",
    "axs[0].set_title('P Residual vs Log P SNR')\n",
    "cbar_p = fig.colorbar(sc_p, ax=axs[0], boundaries=bounds, ticks=bounds)\n",
    "cbar_p.set_label('P Probability')\n",
    "\n",
    "# Plot for S data\n",
    "sc_s = axs[1].scatter(df_s['S_terr'], df_s['log_Ssnr'], c=df_s['Sproba'], cmap=cmap_s, norm=norm, edgecolor='black')\n",
    "axs[1].set_xlabel('S Residual (manual-phasnet)')\n",
    "axs[1].set_ylabel('Log S SNR')\n",
    "axs[1].set_title('S Residual vs Log S SNR')\n",
    "cbar_s = fig.colorbar(sc_s, ax=axs[1], boundaries=bounds, ticks=bounds)\n",
    "cbar_s.set_label('S Probability')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e049d8cb-f941-4dab-8105-98b11db47b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_p = df_picks.dropna(subset=['Pproba', 'Psnr'])\n",
    "df_s = df_picks.dropna(subset=['Sproba', 'Ssnr'])\n",
    "\n",
    "df_p['log_Psnr'] = np.log10(df_p['Psnr'])\n",
    "df_s['log_Ssnr'] = np.log10(df_s['Ssnr'])\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_p['P_terr'], df_p['log_Psnr'], color='blue', label='Pproba vs log(Psnr)')\n",
    "plt.scatter(df_s['S_terr'], df_s['log_Ssnr'], color='red', label='Sproba vs log(Ssnr)')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Log Signal-to-Noise Ratio (log SNR)')\n",
    "plt.title('Scatter Plot of Probabilities vs Log SNR')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.10 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
