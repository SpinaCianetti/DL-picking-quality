#!/bin/bash
source ~/.profile

# 20230822 - Anthony Lomax, ALomax Scientific

# script to run NLL-coherence locations



#
# =========================================================================================================================
# Python environment activation
# # IMPORTANT: you need to modify these commands depending on your operating system
#
# Mac OS
# CondaError: Run 'conda init' before 'conda activate'
# https://stackoverflow.com/questions/55507519/python-activate-conda-env-through-shell-script
source /Applications/anaconda3/etc/profile.d/conda.sh
#
conda activate nll_ssst_coh_3


# USER VARIABLES TO EDIT =================================================================

# IMPORTANT: see also USER VARIABLES TO EDIT below in "cross-correlation coherence analysis"

# identifier for a particular run
RUN_NAME=20240704C_coherence

#
# original locations (must already have been generated, eg. with run_ssst_relocations.bash)
#
# SSST location file root name, will be used for output directory naming and root of output location files
LOC_ROOT=Norcia_2016
# SSST file path without location file root name (from run_ssst_relocations.log); will be used as SSST reference events
# 	WARNING: this directory will be modified with added *.stream_coherences files generated by get_coherence.py
LOC_PATH=/Users/anthony/work_temp/nlloc_tmp/Norcia_2016/20240704C_SSST/Norcia_2016_Tan2021_smooth_SSST/loc_ssst_corr5/NEW_PN_INSTANCE28
# SSST time path/root (from run_ssst_relocations.log); 
# 	will be used to calculate travel-times for cross-correlation coherence analysis and for final, NLL-coherence relocation
TIME_PATH_ROOT=/Users/anthony/work_temp/nlloc_tmp/Norcia_2016/20240704C_SSST/Norcia_2016_Tan2021_smooth_SSST/ssst_corr4/NEW_PN_INSTANCE28/Tan2021_smooth

# model name, will be used for output directory naming
MODEL_NAME=Tan2021_smooth
# sub-region name, will be used for output directory naming
CLUSTER_NAME="Norcia_2016"

# output
OUTPATH_ROOT=out/${RUN_NAME}/coherence/${MODEL_NAME}/${CLUSTER_NAME}

#
# for rectangular grids
SWAP_BYTES=0
# for spherical/global grids with TauP times
#SWAP_BYTES=1
# NLLoc control file INCLUDE with station correction file *.stat_totcorr, not needed if time files from SSST
STA_CORR_ORIG_LOC=
# extra INCLUDE statement, if needed
INCLUDE1=
# if running spherical/global grids with TauP times and DEFAULT station names, set following with LOCSRCE list file,
#   if LOCSRCE's specified with INCLUDE and not directly listed in original control file :
#INCLUDE1="INCLUDE Landers_1992_LOCSRCE.in"
# NLLoc parameters for cluster posterior location, usually same as LSGRID and LSOUTGRID in SSST *_Loc2ssst.in control file.
LOC_GRID="LOCGRID  69 59 35  -18.0 -15.0 -2.0  0.5 0.5 0.5  PROB_DENSITY SAVE"
# set LOC_SEARCH init_num_cells_x/y/z as fine as possible (e.g. so init_num_cells_x*y*z > ~10000) to avoid that
#   oct-tree search gets trapped in a local minimum for poor stacked locations with large pdf extent
LOC_SEARCH="LOCSEARCH OCT 34 29 17 0.001 50000 1000 0 0"

# channel names for cross-correlation coherence analysis
# http://ds.iris.edu/gmap/#channel=EHZ,HHZ&starttime=2016-08-15&endtime=2016-08-15&latitude=42.83&longitude=13.11&maxradius=.25&network=*&datacenter=INGV&drawingmode=radial&planet=earth
# IV INGV
#20240403#TARGET_NSLCS_1=IV_CESI_--_HHZ,IV_FDMO_--_HHZ,IV_LNSS_--_HHZ,IV_MC2_--_EHZ,IV_MMO1_--_EHZ,IV_NRCA_--_HHZ
#TARGET_NSLCS_1=IV_CESI_--_HHZ,IV_FDMO_--_HHZ,IV_LNSS_--_HHZ,IV_MMO1_--_EHZ,IV_T1299_--_EHZ,IV_ARRO_--_EHZ,IV_OFFI_--_HHZ,IV_ASSB_--_HHZ,IV_MOMA_--_HHZ,IV_NRCA_--_HHZ,IV_MC2_--_EHZ   #20240403
TARGET_NSLCS_1=IV_CESI_--_HHZ,IV_FDMO_--_HHZ,IV_LNSS_--_HHZ,IV_MMO1_--_EHZ,IV_T1299_--_EHZ,IV_ARRO_--_EHZ,IV_OFFI_--_HHZ,IV_ASSB_--_HHZ,IV_NRCA_--_HHZ,IV_MC2_--_EHZ   #20240704 MOMA no data
TARGET_NSLCS=${TARGET_NSLCS_1};FDSN_DATASELECT_BASE_URL=https://webservices.ingv.it
#NOT AVAILABLE??? #IV_AQT1_--_EHZ,8P_T1241_--_EHZ,8P_T1242_--_HHZ,8P_T1212_--_EHZ,8P_T1213_--_EHZ,8P_T1214_--_EHZ,8P_T1216_--_EHZ,8P_T1245_--_HHZ;FDSN_DATASELECT_BASE_URL=https://webservices.ingv.it
#
# YR IRIS
##TARGET_NSLCS_2=YR_ED10_--_HHZ,YR_ED11_--_HHZ,YR_ED12_--_HHZ,YR_ED16_--_HHZ,YR_ED19_--_HHZ,YR_ED23_--_HHZ,YR_ED24_--_HHZ;FDSN_DATASELECT_BASE_URL=http://service.iris.edu
##TARGET_NSLCS=${TARGET_NSLCS_2};FDSN_DATASELECT_BASE_URL=http://service.iris.edu
# no waveforms available: 
TARGET_COORDS=""
# if running spherical/global grids with TauP times and DEFAULT station names, set following:
# corresponding station coordinates (comma separated list of lat_lon_elev(km) corresponding to station order in TARGET_NSLCS)
#TARGET_COORDS="--target_coords lat_lon_elev,..."

#
# waveform retrieval (get_streams.py)
# set target waveform start time (seconds before origin time, negative is after origin time) and length
WINDOW_START_WAVEFORM=10
WINDOW_LENGTH_WAVEFORM=60
# sampling rate for resampling waveforms. IMPORTANT: SAMPLING_RATE must be >> FREQMAX used below for cross-correlation coherence analysis !!!
SAMPLING_RATE=50
# base url for FDSN web services
#BASE_URL_OR_SDS_DIR="--base_url http://service.iris.edu"
#BASE_URL_OR_SDS_DIR="--base_url http://service.ncedc.org"
BASE_URL_OR_SDS_DIR="--base_url https://webservices.ingv.it"
FDSN_DATASELECT_OUTPATH=waveform_data/${LOC_ROOT}/fdsn_dataselect/${CLUSTER_NAME}

# application for viewing cross-correlation matrices in png format
PLOT_APP="open -a Preview"

# custom settings for SeismicityViewer
SV_PATH=$(pwd)
#SV_CMD="java -cp SeismicityViewer50.jar:shapefile.jar net.alomax.seismicity.Seismicity"
SV_CMD="java -Xmx2048m net.alomax.seismicity.Seismicity"
SV_ARGS=

# verify also N_PROCESS below

# END - USER VARIABLES TO EDIT =================================================================


WORK_DIR=$(pwd)

mkdir tmp
mkdir -p ${OUTPATH_ROOT}

cp -p run_coherence.bash ${OUTPATH_ROOT}

# NLLoc control file for cluster posterior location
SKELETON_CONF=tmp/NLL.cluster_SKELETON_coherence.conf
# comment out INCLUDE, LOCFILES and LOCGRID in original loc control file and output to SKELETON_CONF
sed '/INCLUDE/ s/^#*/#/' ${LOC_PATH}/last.in > tmp/temp1.conf
sed '/LOCFILES/ s/^#*/#/' tmp/temp1.conf > tmp/temp2.conf
sed '/LOCHYPOUT/ s/^#*/#/' tmp/temp2.conf > tmp/temp3.conf
sed '/LOCGRID/ s/^#*/#/' tmp/temp3.conf > ${SKELETON_CONF}



#
# =========================================================================================================================
# visualize original locations
cd ${SV_PATH}
${SV_CMD} ${LOC_PATH}/${LOC_ROOT}.sum.grid0.loc.hyp ${SV_ARGS} &
cd ${WORK_DIR}



# =========================================================================================================================
# get waveforms (usually does not need to be repeated unless model or LOC_PATH events changed)
#if [ NO = YES ]; then
if [ YES = YES ]; then
	mkdir -p ${FDSN_DATASELECT_OUTPATH}
	declare -i INDEX=0
	unset PIDS
	for TARGET_NSLC in ${TARGET_NSLCS//,/ } ; do
	echo "Running: ${INDEX} ${TARGET_NSLC}"
	python nll_ssst_coh_3/get_streams.py ${BASE_URL_OR_SDS_DIR} --outpath ${FDSN_DATASELECT_OUTPATH} --event_files "${LOC_PATH}/*.*.*.grid0.loc.hyp" --target_nslc ${TARGET_NSLC} --window_start ${WINDOW_START_WAVEFORM} --window_length ${WINDOW_LENGTH_WAVEFORM} --sampling_rate ${SAMPLING_RATE} --no_overwrite 
# 20240404 TEMP FIX: https://webservices.ingv.it Errors and Time outs !!! Do each channel separately # &
	PIDS[${INDEX}]=$!
	INDEX=INDEX+1
	sleep 2
	done
	# wait for all PIDS
	for PID in ${PIDS[*]}; do
		wait ${PID}
		status=$?
		echo "Finished: PID=${PID} status=${status} ================================="
	done
fi


# set definitive channels
##TARGET_NSLCS=${TARGET_NSLCS_1},${TARGET_NSLCS_2}
TARGET_NSLCS=${TARGET_NSLCS_1}
echo "TARGET_NSLCS: ${TARGET_NSLCS}"


# =========================================================================================================================
# cross-correlation coherence analysis

# USER VARIABLES TO EDIT =================================================================
# minimum and maximum frequencies for bandpass (uses obspy.core.trace.Trace.filter('bandpass'))
FREQMIN=2
FREQMAX=10
##FREQMIN=1
##FREQMAX=5
# eqcorrscan.utils.clustering.cross_chan_coherence parameter: shift_len (sec) to shift
DISTANCE_MATRIX_SHIFT_LEN=4.0
# maximum distance in km between epicenters to apply correlation
#COHERENCE_MAX_DIST=2.0  # SOME setting
#COHERENCE_MAX_DIST=5.0  # new SOME setting 20240401
#COHERENCE_MAX_DIST=2.5  # 20240704
COHERENCE_MAX_DIST=5.0  # 20241026
# maximum depth difference in km between hypocneters to apply correlation
COHERENCE_MAX_DEPTH_DIFF=5.0 # 20240704
# minimum coherence to output in NLLoc *.stream_coherences files
COHERENCE_MIN=0.45
# if set, uses abs(coherency) as coherence measure, i.e. reverse polarity traces will give positive coherency
#USE_ABS=
##
USE_ABS="--use_abs"
# if set, does not normalize trace to P and S peaks. Use if only P or only S waves have high signal/noise ratio.
NO_NORMALIZE_PS=
#NO_NORMALIZE_PS="--no_normalize_ps_window"
# S/N ratio check for accepting traces. Ratio of signal max to noise rms, where noise is before and signal is after (P time - snr_p_pad)
SNR_ACCEPT_TRACE="--snr_accept_trace -1 --snr_p_pad 1.0"
# END - USER VARIABLES TO EDIT =================================================================

TEST_NAME=001_${FREQMIN//,/#}-${FREQMAX//,/#}Hz_dmsl${DISTANCE_MATRIX_SHIFT_LEN}_cmd${COHERENCE_MAX_DIST}_cdd${COHERENCE_MAX_DEPTH_DIFF}_cm${COHERENCE_MIN}
if [[ ${USE_ABS}} == --* ]]; then TEST_NAME=${TEST_NAME}_abs; fi
if [[ ${NO_NORMALIZE_PS}} == --* ]]; then TEST_NAME=${TEST_NAME}_nnorm; fi
if [[ ${SNR_ACCEPT_TRACE}} == --* ]]; then TEST_NAME=${TEST_NAME}_snr; fi

OUTPATH=${OUTPATH_ROOT}/${TEST_NAME}

#rm -r ${OUTPATH}
mkdir -p ${OUTPATH}
cp -p run_coherence.bash  ${OUTPATH}
cp -p nll_ssst_coh_3/get_coherence.py  ${OUTPATH}

NLL_PATH_ROOT_COHERENCE_POSTERIOR=${LOC_PATH}/${LOC_ROOT}


# get coherences
NLL_TRANS=$(awk '$1!~/^#/ && $1~"TRANS"' ${WORK_DIR}/${SKELETON_CONF})
export PYTHONPATH=nll_ssst_coh_3
# base call to get_coherence.py with common arguments
BASE_GET_COHERENCE="python nll_ssst_coh_3/get_coherence.py --bandpass_freqmin ${FREQMIN} --bandpass_freqmax ${FREQMAX} --outpath ${OUTPATH} --nll_hyp_root ${NLL_PATH_ROOT_COHERENCE_POSTERIOR} --distance_matrix_shift_len ${DISTANCE_MATRIX_SHIFT_LEN}  --max_dist ${COHERENCE_MAX_DIST} --max_depth_diff ${COHERENCE_MAX_DEPTH_DIFF} --coherence_min ${COHERENCE_MIN} --coherency_matrix ${OUTPATH} ${USE_ABS} --ps_window_size 1.0 --ps_window_pad_min ${DISTANCE_MATRIX_SHIFT_LEN} --ps_window_reject --nll_time_path_root ${TIME_PATH_ROOT} ${NO_NORMALIZE_PS} --nll_no_net_code  ${SNR_ACCEPT_TRACE}"
#
if [ ALL = ALL ]; then
    # get coherence for all channels in parallel
    ctmp="${TARGET_NSLCS//[^,]}"  # remove everything but the delimiter ','
    declare -i NUM_CORES=${#ctmp}+1          # get the number of elements
    #NUM_CORES=2   #DEBUG!!!
    ${BASE_GET_COHERENCE} --target_nslc ${TARGET_NSLCS} --num_cores ${NUM_CORES} --trace_roots "${FDSN_DATASELECT_OUTPATH}/*.*.*" --nll_trans "${NLL_TRANS}"
else
    # get coherence for individual channels, use if Python parallel processing locks up (!), but uses much more memory
    declare -i INDEX=0
    unset PIDS
    for TARGET_NSLC in ${TARGET_NSLCS//,/ } ; do
    ${BASE_GET_COHERENCE} --target_nslc ${TARGET_NSLC} --no_accumulate_event_coherences --trace_roots "${FDSN_DATASELECT_OUTPATH}/*.*.*" --nll_trans "${NLL_TRANS}" &
    PIDS[${INDEX}]=$!
    INDEX=INDEX+1
    sleep 2
    done
    # wait for all PIDS
    for PID in ${PIDS[*]}; do
        wait ${PID}
        status=$?
        echo "Finished: PID=${PID} status=${status} ================================="
    done
    #
    # accumulate event coherences
    ${BASE_GET_COHERENCE} --target_nslc ${TARGET_NSLCS} --trace_roots "${FDSN_DATASELECT_OUTPATH}/*.*.*" --nll_trans "${NLL_TRANS}"
fi

echo "${PLOT_APP} ${OUTPATH}/distances*.png"
${PLOT_APP} ${OUTPATH}/distances*.png


#
# =========================================================================================================================
# Python environment deactivation
conda deactivate



# =========================================================================================================================
# NLLoc coherence relocation with weighted pdf stacking

# USER VARIABLES TO EDIT =================================================================
# run NLLoc with posterior
# minimum coherence to use for mapping coherence to NLL-coherence pdf stack weight
COHERENCE_MIN_NLL=0.5
# maximum event se3 (ellipsoid.len3) to include event in pdf stack. Use negative value to disable this check.
#   Excludes events with poor location constraint and large pdf extent. Such event pdf's would only contribute noise to stack, 
#   but due to potentially high complexity of stack pdf, including such pdf's may cause oct-tree search to get trapped
#   in a local minimum within this event pdf (especially if LOC_SEARCH init_num_cells_x/y/z are too few). When this trapping occurs, some NLL-coherence events may cluster far from 
#   any events in SSST reference events (LOC_PATH), with unusual epicenter or depth.
#   May typically have same or similar value as COHERENCE_MAX_DIST
MAX_SE3=5.0
# maximum total of coherence weight for other events; if exceeded, other event coherences normalized to sum to this value
# 	recommended value is -1.0, disabled.
MAX_TOTAL_OTHER_WEIGHT=-1.0
##MAX_TOTAL_OTHER_WEIGHT=4.0
# maximum number of other events to include in pdf stack, Use negative value for no limit.
#    limit processing time and number of files open when a large number of events have high coherency.
##MAX_COUNT_OTHER=-1
##
MAX_COUNT_OTHER=25
# maximum magnitude difference to include other event in pdf stack (-1.0 to disable).
#   Excludes events that are not likely to have waveform similarity with target due to differences in spectral peak.
#   May help avoid false high correlation due to filtering or clipping.
MAX_MAG_DIFF=-1.0
###MAX_MAG_DIFF=1.0
# minimum magnitude to process event (-999 to disable).
#   Enables not processing smaller magnitude events, e.g. for avoiding possible noisy waveforms or for speeding up testing.
MIN_MAG=-999
###MIN_MAG=2.0
# specify the number of NLLoc instances to be run in parallel (e.g. up to 2 times the number of pyhsical CPU cores available)
N_PROCESS=16
#N_PROCESS=12
#N_PROCESS=8
# END - USER VARIABLES TO EDIT =================================================================

OUTPATH_COH=${OUTPATH}_coh${COHERENCE_MIN_NLL}
if [[ ${MAX_SE3}} != -* ]]; then OUTPATH_COH=${OUTPATH_COH}_se${MAX_SE3}; fi
if [[ ${MAX_TOTAL_OTHER_WEIGHT}} != -* ]]; then OUTPATH_COH=${OUTPATH_COH}_mtow${MAX_TOTAL_OTHER_WEIGHT}; fi
if [[ ${MAX_COUNT_OTHER}} != -* ]]; then OUTPATH_COH=${OUTPATH_COH}_mco${MAX_COUNT_OTHER}; fi
if [[ ${MAX_MAG_DIFF}} != -* ]]; then OUTPATH_COH=${OUTPATH_COH}_dM${MAX_MAG_DIFF}; fi
if [[ ${MIN_MAG}} != -* ]]; then OUTPATH_COH=${OUTPATH_COH}_mm${MIN_MAG}; fi

#RESTART (comment following line)#
rm -r ${OUTPATH_COH} 2> /dev/null

mkdir -p ${OUTPATH_COH}
TEMP_DIR=${OUTPATH_ROOT}/tmpdir
mkdir ${TEMP_DIR}
declare -i IRUN_COUNT=0
# run in parallel
# https://unix.stackexchange.com/questions/103920/parallelize-a-bash-for-loop
parallel_task() {
	NLLoc $1
}
(
for EVENT_FILE in ${NLL_PATH_ROOT_COHERENCE_POSTERIOR}.*.*.grid0.loc.hyp ; do
#for EVENT_FILE in ${NLL_PATH_ROOT_COHERENCE_POSTERIOR}.20040928.184815.grid0.loc.hyp ; do

#RESTART#if [ $((${IRUN_COUNT} > 5280)) = 1 ]; then

	CRUN_COUNT='000000'${IRUN_COUNT}      # get number, pack with zeros
	CRUN_COUNT=${CRUN_COUNT:(-6)}       # the last five characters

	EVENT=${EVENT_FILE#${NLL_PATH_ROOT_COHERENCE_POSTERIOR}.}
	EVENT=${EVENT%.grid0.loc.hyp}
	##echo ${EVENT}
	EVENT_ROOT=${NLL_PATH_ROOT_COHERENCE_POSTERIOR}.${EVENT}.grid0.loc
	cp ${SKELETON_CONF} ${TEMP_DIR}/NLL.${LOC_ROOT}_coherence_${CRUN_COUNT}.conf 
	cat << END >> ${TEMP_DIR}/NLL.${LOC_ROOT}_coherence_${CRUN_COUNT}.conf 
CONTROL 0 54321
LOCCOM ${OUTPATH_COH}
LOCFILES ${EVENT_ROOT}.hyp NLLOC_OBS ${TIME_PATH_ROOT} ${OUTPATH_COH}/${CRUN_COUNT}/${LOC_ROOT} ${SWAP_BYTES}
LOCHYPOUT SAVE_NLLOC_ALL  NLL_FORMAT_VER_2  SAVE_HYPOINV_SUM  SAVE_FMAMP
${LOC_GRID}
${LOC_SEARCH}
LOCPOSTERIOR  OCT_TREE  ${EVENT_ROOT}.stream_coherences  1e-30  ${COHERENCE_MIN_NLL}  ${MAX_TOTAL_OTHER_WEIGHT}  ${MAX_SE3}  ${MAX_COUNT_OTHER}  ${MAX_MAG_DIFF}  ${MIN_MAG}
# !!! staCorr from original locations, not needed if SSST time files
${STA_CORR_ORIG_LOC}
${INCLUDE1}
END
	mkdir ${OUTPATH_COH}/${CRUN_COUNT}
	#gdb --args 
	#lldb -f 
	
    # Parallel runs in N_PROCESS batches
    # https://unix.stackexchange.com/questions/103920/parallelize-a-bash-for-loop
	((i=i%N_PROCESS)); ((i++==0)) && wait
	parallel_task ${TEMP_DIR}/NLL.${LOC_ROOT}_coherence_${CRUN_COUNT}.conf & 
	
#RESTART#fi

	IRUN_COUNT=IRUN_COUNT+1

done
wait
)
rm -r ${OUTPATH_ROOT}/tmpdir
# copy sum files from each event location to sum_ALL
cd ${OUTPATH_COH}
find . -name "${LOC_ROOT}.sum.grid0.loc.hyp" -print0 | sort | xargs -0 cat > ${LOC_ROOT}.sum_ALL.grid0.loc.hyp
find . -name "${LOC_ROOT}.sum.grid0.loc.fmamp" -print0 | sort | xargs -0 cat > ${LOC_ROOT}.sum_ALL.grid0.loc.fmamp
cd ${WORK_DIR}

cd ${SV_PATH}
echo "${SV_CMD} ${OUTPATH_COH}/${LOC_ROOT}.sum_ALL.grid0.loc.hyp ${SV_ARGS} &"
${SV_CMD} ${OUTPATH_COH}/${LOC_ROOT}.sum_ALL.grid0.loc.hyp ${SV_ARGS} &
cd ${WORK_DIR}

cat >> coherence.list << END
${OUTPATH_COH}/${LOC_ROOT}.sum_ALL.grid0.loc.hyp
END

